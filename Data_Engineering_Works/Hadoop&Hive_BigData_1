
======================================================================================================================================
====== Moving all the files from local to HDFS

hadoop fs -copyFromLocal /root/Desktop/user_repo/Datasets/* hdfs://localhost:9000/user/Datasets/

====== Moving all the files from HDFS to Local

hadoop fs -copyToLocal hdfs://localhost:9000/user/Out_1/part_file.csv /root/Desktop/user_repo/Output/out_1

== above command used to copy data present in part file into out_1 file 

========= Creating the directo

======================================================================================================================================


======================================================================================================================================


======================================================================================================================================

======================================================================================================================================


======================================================================================================================================

======================================================================================================================================

======================================================================================================================================


======================================================================================================================================


# To use into hive environment

/usr/bin/hive

// hive query 

select * from database.table limit 10;

=====================================================================================================================================

# Creation of Shell scripts in hive 

/usr/bin/hive <<EOF

println("LOG: OUTPUT TABLE -------")

println("LOG:col  :"+ select count(*)  from database.table where col IS NULL)

EOF

# Hive shell script to check the error log in the log files created in the HDFS path 

if grep -l error *.log; then
        echo "THERE ARE ERRORS IN THE EXTRACT"
fi

=====================================================================================================================================

To Run .hql files from hive ::(.hql files you can write sql commands)

hive -f /home/<path to hive file>/filename.hql
hive -f /home/<path to hive file>/filename.hql

// hive command to remove table from database using shell scripting

hive -e "drop table databasename.tablename"
=====================================================================================================================================
=====================================================================================================================================

# Hadoop commands

# == To list out the directories and files present in this path
hadoop fs -ls adl://<azure data lake storge>/data/mo/qa

// removing the files present in hdfs path 

hdfs dfs -rm -r /hive/warehouse/databasename.db/table_dir
=====================================================================================================================================

# Moving the large datasets between two clueters in hadoop using distcp  
#move current dbs to restore folder (with renaming)
#current DB -> Restore Folder 

current_folder_path='<ADLS path link>'
backup_folder_path='<ADLS path link>'
restore_folder_path='<ADLS path link>'

hadoop distcp $current_folder_path/quality_compute.db $restore_folder_path/databasename_1.db
hadoop distcp $current_folder_path/quality_primary.db $restore_folder_path/databasename_2.db

=====================================================================================================================================


# Cleaning the current folder after moving
# clean up current folder
#delete files from existing location

hadoop fs -rm -r $current_folder_path/databasename_1.db
hadoop fs -rm -r $current_folder_path/databasename_2.db


=====================================================================================================================================

# For Schema check

describe tablename; 

# For tables in Database

describe databasename

=====================================================================================================================================

# Select funtion in hive 

select num,
    collectUDAF(id, values) as new_map 
from
    ( SELECT num,id,collect_set(value) as values FROM tbl GROUP BY num,id ) as sub GROUP BY num

=====================================================================================================================================
// TO know the usage of keys in hive we can get description of keys as below

$ /usr/bin/hive -H
usage: hive
 -d,--define <key=value>          Variable subsitution to apply to hive
                                  commands. e.g. -d A=B or --define A=B
    --database <databasename>     Specify the database to use
 -e <quoted-query-string>         SQL from command line
 -f <filename>                    SQL from files
 -H,--help                        Print help information
    --hiveconf <property=value>   Use value for given property
    --hivevar <key=value>         Variable subsitution to apply to hive
                                  commands. e.g. --hivevar A=B
 -i <filename>                    Initialization SQL file
 -S,--silent                      Silent mode in interactive shell
 -v,--verbose                     Verbose mode (echo executed SQL to the
                                  console)
                                  
=====================================================================================================================================
                                
# TO DELETE ALL THE LINES IN SCRIPT :::	

In vi I use

:%d
where

: tells vi to go in command mode
% means all the line
d : delete
On the command line,



====================== Creating table and storing it in specific path

drop table databasename.tablename;
CREATE TABLE databasename.tablename(
`col_1` double,
`col_2` string,
`col_3` double,
`col_4` double,
`col_5` string,
`col_6` TIMESTAMP,
`col_7` string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
location 'wasbs://quantumbrserver@quantumb.blob.core.windows.net/data/issue_driver/Univ_Contrib'

tblproperties("skip.header.line.count"="1");
